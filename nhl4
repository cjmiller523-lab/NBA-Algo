# nhl4_apiweb.py ‚Äî NHL hit-rate engine using api-web.nhle.com only
import os
import json
import time
import argparse
from datetime import datetime
from collections import defaultdict

import requests

# =========================
# SETTINGS
# =========================
LAST_N_GAMES = 10
SEASON = "20242025"           # api-web format, e.g., 20242025 (Regular Season = gameType 2)
GAME_TYPE = "2"               # 2 = Regular Season, 3 = Playoffs
MAX_RETRIES = 3
RETRY_SLEEP = 0.7

CACHE_DIR = "cache_nhl"
LOGS_DIR = os.path.join(CACHE_DIR, "logs", SEASON)
ROSTERS_PATH = "nhl_rosters.json"
INJURIES_PATH = "nhl_out_statuses.json"
ODDS_CACHE_DIR = "odds_cache"
TWITTER_DIR = "twitter_posts"

MARKETS = ["SOG", "PTS", "AST", "GLS"]
THRESHOLDS = {
    "SOG": [1, 2, 3, 4, 5, 6, 7],
    "PTS": [0.5, 1.5, 2.5, 3.5],
    "AST": [0.5, 1.5, 2.5],
    "GLS": [0.5, 1.5, 2.5],
}
ODDS_WINDOW = (-1500, -150)   # inclusive
REQUIRE_100 = True
TOP_K_PER_GAME = 3

# =========================
# UTILS
# =========================
def ensure_dirs():
    os.makedirs(LOGS_DIR, exist_ok=True)
    os.makedirs(TWITTER_DIR, exist_ok=True)
    os.makedirs(ODDS_CACHE_DIR, exist_ok=True)

def http_get(url, params=None, retries=MAX_RETRIES, sleep=RETRY_SLEEP):
    last = None
    for i in range(retries):
        try:
            r = requests.get(url, params=params, timeout=20)
            if r.status_code == 200:
                return r.json()
            last = f"HTTP {r.status_code} for {url}"
        except requests.RequestException as e:
            last = str(e)
        time.sleep(sleep * (i + 1))
    raise RuntimeError(last or f"GET failed for {url}")

def american_in_window(odds, low=ODDS_WINDOW[0], high=ODDS_WINDOW[1]):
    try:
        return odds is not None and low <= odds <= high
    except:
        return False

def fmt_american(odds):
    if odds is None:
        return "N/A"
    return f"+{odds}" if odds > 0 else str(odds)

def pick_best_price(entries):
    # entries: list of {line, odds}. Choose the "strongest" negative (more favored) by default.
    if not entries:
        return None
    best = entries[0]
    for e in entries[1:]:
        if e.get("odds") is None: 
            continue
        if best.get("odds") is None or e["odds"] < best["odds"]:
            best = e
    return best

# =========================
# API-WEB ENDPOINTS
# =========================
def apiweb_score_now():
    return http_get("https://api-web.nhle.com/v1/score/now")

def apiweb_score_date(date_str):
    # Works for specific day; if it fails, caller should fall back to score/now on mismatch-day
    return http_get(f"https://api-web.nhle.com/v1/score/{date_str}")

def apiweb_roster(team_abbrev, season=SEASON, site="en_nhl"):
    return http_get(f"https://api-web.nhle.com/v1/roster/{team_abbrev}/{season}", params={"site": site})

def apiweb_player_gamelog(player_id, season=SEASON, game_type=GAME_TYPE):
    return http_get(f"https://api-web.nhle.com/v1/player/{player_id}/game-log/{season}/{game_type}")

# =========================
# DATA PIPELINE
# =========================
def load_injuries(path=INJURIES_PATH):
    if os.path.exists(path):
        try:
            with open(path, "r", encoding="utf-8") as f:
                data = json.load(f)
            return set(data) if isinstance(data, list) else set()
        except:
            return set()
    return set()

def load_odds_cache(date_str):
    fp = os.path.join(ODDS_CACHE_DIR, f"nhl_{date_str}.json")
    if os.path.exists(fp):
        try:
            with open(fp, "r", encoding="utf-8") as f:
                root = json.load(f)
            return root.get(date_str, {})
        except:
            return {}
    return {}

def schedule_for_date(date_str):
    """Return list of games: [{'home': 'BOS', 'away': 'NYR', 'gameId': '2024020345'}]"""
    games = []
    try:
        data = apiweb_score_date(date_str)
    except:
        data = apiweb_score_now()
        # Only keep currentDate games if mismatch
        if data.get("currentDate") != date_str:
            return []
    # api-web "games" live under something like data['games'] when using score/{date}
    # On score/now they‚Äôre under data['games'] too (for currentDate).
    for g in data.get("games", []):
        away_abbr = g.get("awayTeam", {}).get("abbrev")
        home_abbr = g.get("homeTeam", {}).get("abbrev")
        gid = g.get("id") or g.get("gameId")
        if away_abbr and home_abbr:
            games.append({"away": away_abbr, "home": home_abbr, "gameId": gid})
    return games

def build_or_load_rosters(path=ROSTERS_PATH, teams=None):
    """
    Build a {fullName: {id, team, pos}} map using api-web rosters, or load from disk if present.
    'teams' is the set of team abbrevs playing today (to keep this fast).
    """
    if os.path.exists(path):
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)

    if not teams:
        raise RuntimeError("Teams list is required to build rosters on first run.")

    print("üîß Building nhl_rosters.json from api-web‚Ä¶")
    mapping = {}
    for t in sorted(teams):
        try:
            roster = apiweb_roster(t)
            # Expected shape: {"forwards":[{...}], "defensemen":[{...}], "goalies":[{...}]}
            for bucket in ("forwards", "defensemen", "goalies"):
                for p in roster.get(bucket, []):
                    pid = p.get("playerId") or p.get("id")
                    name = p.get("firstName", {}).get("default", "") + " " + p.get("lastName", {}).get("default", "")
                    name = name.strip()
                    pos = p.get("position", {}).get("code") or p.get("positionCode") or bucket[:1].upper()
                    if pid and name:
                        mapping[name] = {"id": pid, "team": t, "pos": pos}
            time.sleep(0.08)
        except Exception as e:
            print(f"  ‚ö†Ô∏è Roster fetch failed for {t}: {e}")

    with open(path, "w", encoding="utf-8") as f:
        json.dump(mapping, f, indent=2, ensure_ascii=False)
    return mapping

def player_log_cached(player_id):
    fp = os.path.join(LOGS_DIR, f"{player_id}.json")
    if os.path.exists(fp):
        with open(fp, "r", encoding="utf-8") as f:
            return json.load(f)
    return None

def save_player_log(player_id, payload):
    fp = os.path.join(LOGS_DIR, f"{player_id}.json")
    with open(fp, "w", encoding="utf-8") as f:
        json.dump(payload, f, indent=2, ensure_ascii=False)

def extract_recent_stats_apiweb(gamelog_json, last_n=LAST_N_GAMES):
    """Return list of dicts: [{SOG, GLS, AST, PTS, date, opp, team}] most-recent first, sliced to last_n."""
    out = []
    # api-web gamelog payload typically has 'gameLog' as a list
    logs = gamelog_json.get("gameLog", []) or gamelog_json.get("gameLogBySeason", []) or []
    for s in logs:
        stat = s.get("boxscore", {}) or s  # some payloads nest stats under 'boxscore'
        # Common keys
        sog = stat.get("shots", 0)
        g = stat.get("goals", 0)
        a = stat.get("assists", 0)
        pts = stat.get("points", (g or 0) + (a or 0))
        opp = s.get("opponentAbbrev") or s.get("opponent", {}).get("abbrev")
        team = s.get("teamAbbrev") or s.get("team", {}).get("abbrev")
        date = s.get("gameDate") or s.get("gameDateUTC") or s.get("gameDateTime")
        out.append({"SOG": sog or 0, "GLS": g or 0, "AST": a or 0, "PTS": pts or 0,
                    "opp": opp, "team": team, "date": date})
    return out[:last_n]

def compute_hit_rate(recent, market, threshold):
    vals = [r[market] for r in recent]
    hits = sum(1 for v in vals if v >= threshold)
    total = len(vals)
    return hits, total

def best_threshold(recent, market):
    best = None
    for th in THRESHOLDS[market]:
        h, t = compute_hit_rate(recent, market, th)
        ratio = (h / t) if t else 0.0
        cand = (ratio, th, h, t)
        if best is None or cand > best:
            best = cand
    return best  # (ratio, th, hits, total)

def bounce_back_flag(recent, market, high_bar=0.8):
    if not recent:
        return False
    default_th = THRESHOLDS[market][0]  # light default
    last_val = recent[0][market]
    last_hit = last_val >= default_th
    h, t = compute_hit_rate(recent, market, default_th)
    overall = (h / t) if t else 0.0
    return (not last_hit) and (overall >= high_bar)

# =========================
# MAIN
# =========================
def main():
    ensure_dirs()

    parser = argparse.ArgumentParser(description="NHL Hit-Rate Engine (api-web.nhle.com)")
    parser.add_argument("--date", type=str, default=datetime.now().strftime("%Y-%m-%d"),
                        help="Date to run (YYYY-MM-DD). Uses score/{date} if not today.")
    parser.add_argument("--season", type=str, default=SEASON, help="Season code, e.g., 20242025")
    parser.add_argument("--last", type=int, default=LAST_N_GAMES, help="Window size for hit-rate")
    args = parser.parse_args()

    date_str = args.date
    season = args.season
    last_n = max(1, args.last)

    print("üîç Fetching NHL schedule‚Ä¶")
    games = schedule_for_date(date_str)
    print(f"Number of games: {len(games)}")

    if not games:
        txt_path = os.path.join(TWITTER_DIR, f"{date_str}.txt")
        with open(txt_path, "w", encoding="utf-8") as f:
            f.write(f"{date_str}\nNo NHL games.")
        print(f"üìÑ Twitter text saved to {txt_path}")
        return

    all_teams_today = set()
    for g in games:
        all_teams_today.add(g["home"])
        all_teams_today.add(g["away"])

    injuries = load_injuries()
    odds_map = load_odds_cache(date_str)

    # Build or load rosters scoped to today's teams
    rosters = build_or_load_rosters(ROSTERS_PATH, teams=all_teams_today)

    # Quick index: team -> [(name, id)]
    team_to_players = defaultdict(list)
    for name, meta in rosters.items():
        team_to_players[meta["team"]].append((name, meta["id"]))

    # Aggregation structures
    per_game_results = defaultdict(lambda: defaultdict(list))  # game_key -> market -> rows
    global_100 = []    # (name, team, market, th, hits, total, odds, gk)
    bounce_list = []   # (name, team, market, gk)

    print("üì• Pulling player logs (cache-first, api-web)‚Ä¶")
    for team in sorted(all_teams_today):
        for (full_name, pid) in team_to_players.get(team, []):
            if full_name in injuries:
                continue

            payload = player_log_cached(pid)
            if payload is None:
                try:
                    payload = apiweb_player_gamelog(pid, season=season, game_type=GAME_TYPE)
                    save_player_log(pid, payload)
                    time.sleep(0.06)
                except Exception as e:
                    # Skip player if log fetch fails
                    continue

            recent = extract_recent_stats_apiweb(payload, last_n=last_n)
            if not recent:
                continue

            # Determine today's game key for the player
            gk = None
            for gm in games:
                if team == gm["home"]:
                    gk = f"{gm['away']}@{gm['home']}"
                    break
                if team == gm["away"]:
                    gk = f"{gm['away']}@{gm['home']}"
                    break
            if not gk:
                continue

            # Odds for this player (if any)
            player_odds = odds_map.get(full_name, {})

            for M in MARKETS:
                ratio, th, hits, total = best_threshold(recent, M)
                best_odds_entry = pick_best_price(player_odds.get(M, [])) if player_odds else None
                american = best_odds_entry.get("odds") if best_odds_entry else None

                per_game_results[gk][M].append({
                    "player": full_name,
                    "team": team,
                    "market": M,
                    "threshold": th,
                    "hits": hits,
                    "total": total,
                    "hitrate": round(100 * ratio, 1),
                    "odds": american
                })

                if REQUIRE_100 and total == last_n and hits == last_n and american_in_window(american):
                    global_100.append((full_name, team, M, th, hits, total, american, gk))

                if bounce_back_flag(recent, M, high_bar=0.8):
                    bounce_list.append((full_name, team, M, gk))

    # Sort + trim per-game lists
    for gk in per_game_results:
        for M in per_game_results[gk]:
            per_game_results[gk][M].sort(key=lambda r: (r["hits"] / (r["total"] or 1), r["threshold"]), reverse=True)
            per_game_results[gk][M] = per_game_results[gk][M][:TOP_K_PER_GAME]

    # Sort global locks by odds then name
    global_100.sort(key=lambda t: (abs(t[6]) if t[6] is not None else 10_000, t[0]))

    # =========================
    # PRINT OUTPUT
    # =========================
    print("\n==============================")
    print(f"üèí NHL Props ‚Äî {date_str}")
    print("==============================\n")

    for gm in games:
        gk = f"{gm['away']}@{gm['home']}"
        print(f"==============================\n{gk}\n==============================")
        for M in MARKETS:
            arr = per_game_results.get(gk, {}).get(M, [])
            if not arr:
                continue
            header = {"SOG":"Shots on Goal", "PTS":"Points", "AST":"Assists", "GLS":"Goals"}[M]
            print(f"\n{header}")
            for r in arr:
                print(f"{r['player']} ({r['team']}) - {header} {r['threshold']}+ @ {fmt_american(r['odds'])} | {r['hits']}/{r['total']} ({r['hitrate']}%)")
        print()

    print("\nüî• 100% Locks (odds window)")
    if not global_100:
        print("None.")
    else:
        for (name, team, M, th, hits, total, american, gk) in global_100:
            short = {"SOG":"SOG","PTS":"PTS","AST":"AST","GLS":"GLS"}[M]
            print(f"{name} {short} {th}+ @ {fmt_american(american)} | {hits}/{total} ‚Äî {gk}")

    print("\nüîÅ Global Bounce-Back (missed last, ‚â•80% overall)")
    if not bounce_list:
        print("None.")
    else:
        seen = set()
        for (name, team, M, gk) in bounce_list:
            key = (name, M)
            if key in seen:
                continue
            seen.add(key)
            tag = {"SOG":"SOG","PTS":"PTS","AST":"AST","GLS":"GLS"}[M]
            print(f"{name} ({team}) ‚Äî {tag} ‚Äî {gk}")

    # =========================
    # SAVE TWITTER TEXT
    # =========================
    lines = []
    lines.append(f"{date_str} ‚Äî NHL")
    for gm in games:
        gk = f"{gm['away']}@{gm['home']}"
        gm_sec = per_game_results.get(gk, {})
        if not any(gm_sec.get(M) for M in MARKETS):
            continue
        lines.append("")
        lines.append(gk)
        for M in MARKETS:
            arr = gm_sec.get(M, [])
            if not arr:
                continue
            header = {"SOG":"Shots on Goal", "PTS":"Points", "AST":"Assists", "GLS":"Goals"}[M]
            lines.append(header)
            for r in arr:
                lines.append(f"{r['player']} {header.split()[0]} {r['threshold']}+ @ {fmt_american(r['odds'])} | {r['hits']}/{r['total']}")

    lines.append("\n100% Locks (odds window)")
    if not global_100:
        lines.append("None.")
    else:
        for (name, team, M, th, hits, total, american, gk) in global_100[:12]:
            short = {"SOG":"SOG","PTS":"PTS","AST":"AST","GLS":"GLS"}[M]
            lines.append(f"{name} {short} {th}+ {fmt_american(american)} ‚Äî {gk}")

    txt_path = os.path.join(TWITTER_DIR, f"{date_str}.txt")
    with open(txt_path, "w", encoding="utf-8") as f:
        f.write("\n".join(lines))
    print(f"\nüìÑ Twitter text saved to {txt_path}\n")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nInterrupted.")
