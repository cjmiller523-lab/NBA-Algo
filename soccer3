import os
import re
import json
import time
import random
from datetime import datetime

import pandas as pd
import numpy as np
import requests

# ==========================================================
# ======================= SETTINGS =========================
# ==========================================================
SGO_API_KEY = os.getenv("SGO_API_KEY", "7243468c02f981445249730c03b426c1")

BASE_URL = "https://api.sportsgameodds.com/v2/events"

SPORT_ID = "SOCCER"
LEAGUE_ID = "ENG_PR"     # Premier League (SGO naming)
BOOKMAKER = "fanduel"

NUM_GAMES = 10
CACHE_GAMES = 15
MIN_STARTER_AVG_MIN = 70

WINDOWS = [5, 10, 15]
WINDOW_WEIGHTS = {5: 0.45, 10: 0.35, 15: 0.20}

REQUEST_SLEEP = (0.6, 1.2)

OUT_DIR = "twitter_posts"
CACHE_DIR = "soccer_cache/players"
os.makedirs(OUT_DIR, exist_ok=True)
os.makedirs(CACHE_DIR, exist_ok=True)

# ==========================================================
# ====================== STAT CONFIG =======================
# ==========================================================
STAT_META = {
    "shots": {
        "label": "Shots",
        "df_col": "shots",
        "thresholds": [1, 2, 3, 4, 5],
    },
    "sot": {
        "label": "SOT",
        "df_col": "shots_on_target",
        "thresholds": [1, 2],
    },
}
STATS = list(STAT_META.keys())

# ==========================================================
# ====================== UTILITIES =========================
# ==========================================================
def _sleep():
    time.sleep(random.uniform(*REQUEST_SLEEP))

def _safe(name):
    return name.replace(" ", "_").replace(".", "").replace("'", "").replace("/", "_")

def short_name(name):
    parts = name.split()
    return name if len(parts) < 2 else f"{parts[0][0]}. {parts[-1]}"

def hit_rate(series, thr):
    series = pd.to_numeric(series, errors="coerce").dropna()
    if series.empty:
        return 0.0, 0, 0
    hits = int((series >= thr).sum())
    pct = hits / len(series) * 100
    return round(pct, 1), hits, len(series)

def multi_window_hit_rates(df, col, thr):
    out = {}
    series = pd.to_numeric(df[col], errors="coerce").dropna()
    for w in WINDOWS:
        sub = series.head(w)
        if len(sub) < w:
            out[w] = {"pct": 0.0, "hits": 0}
        else:
            hits = int((sub >= thr).sum())
            out[w] = {"pct": round(hits / w * 100, 1), "hits": hits}
    return out

def stability_score(multi):
    score = 0.0
    for w, d in multi.items():
        score += WINDOW_WEIGHTS[w] * (d["pct"] / 100.0)
    return round(score, 3)

def is_regular_starter(df):
    mins = pd.to_numeric(df["MIN"], errors="coerce").dropna()
    if mins.empty:
        return False
    return mins.head(8).mean() >= MIN_STARTER_AVG_MIN

# ==========================================================
# ====================== CACHING ===========================
# ==========================================================
def cache_path(player):
    return os.path.join(CACHE_DIR, f"{_safe(player)}.json")

def load_player_cache(player):
    path = cache_path(player)
    if not os.path.exists(path):
        return pd.DataFrame()
    try:
        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)
        df = pd.DataFrame(data)
        df["GAME_DATE"] = pd.to_datetime(df["GAME_DATE"])
        return df
    except:
        return pd.DataFrame()

def save_player_cache(player, df):
    path = cache_path(player)
    with open(path, "w", encoding="utf-8") as f:
        json.dump(df.to_dict(orient="records"), f, indent=2, default=str)

# ==========================================================
# ====================== FBREF =============================
# ==========================================================
FBREF_BASE = "https://fbref.com"
PL_STATS_URL = "https://fbref.com/en/comps/9/Premier-League-Stats"
HEADERS = {"User-Agent": "Mozilla/5.0"}

def fetch_html(url):
    _sleep()
    r = requests.get(url, headers=HEADERS, timeout=20)
    r.raise_for_status()
    return r.text

def build_matchlogs_url(href):
    pid = href.split("/")[-2]
    slug = href.split("/")[-1]
    return f"{FBREF_BASE}/en/players/{pid}/matchlogs/all_comps/summary/{slug}-Match-Logs"

def fetch_player_index():
    print("üîç Building Premier League player index (FBref)...")
    html = fetch_html(PL_STATS_URL)
    tables = pd.read_html(html)

    df = next(t for t in tables if "Player" in t.columns and "Squad" in t.columns)

    hrefs = re.findall(r'href="(/en/players/[^"]+)"', html)
    href_map = {}
    for h in hrefs:
        if re.match(r"^/en/players/[A-Za-z0-9]+/[A-Za-z\-]+$", h):
            slug = h.split("/")[-1].lower()
            href_map[slug] = h

    players = []
    for _, r in df.iterrows():
        name = str(r["Player"]).strip()
        team = str(r["Squad"]).strip()
        slug = name.replace(" ", "-").replace("'", "").lower()
        if slug in href_map:
            players.append({
                "name": name,
                "team": team,
                "url": build_matchlogs_url(href_map[slug])
            })

    print(f"‚úÖ Indexed {len(players)} PL players")
    return players

def fetch_matchlogs(url):
    _sleep()
    df = pd.read_html(fetch_html(url))[0]
    df.columns = [c.lower() for c in df.columns]

    col_map = {
        "date": "GAME_DATE",
        "min": "MIN",
        "sh": "shots",
        "sot": "shots_on_target"
    }

    df = df.rename(columns={k: v for k, v in col_map.items() if k in df.columns})
    if "shots_on_target" not in df.columns:
        df["shots_on_target"] = np.nan

    df["GAME_DATE"] = pd.to_datetime(df["GAME_DATE"], errors="coerce")
    df = df.dropna(subset=["GAME_DATE"])
    df = df[["GAME_DATE", "MIN", "shots", "shots_on_target"]]
    df = df.sort_values("GAME_DATE", ascending=False)
    return df

def get_recent_games(player, url):
    cached = load_player_cache(player)
    try:
        fresh = fetch_matchlogs(url).head(CACHE_GAMES)
    except:
        return cached.head(CACHE_GAMES)

    combined = fresh if cached.empty else (
        pd.concat([fresh, cached])
        .drop_duplicates(subset="GAME_DATE")
        .sort_values("GAME_DATE", ascending=False)
        .head(CACHE_GAMES)
    )

    save_player_cache(player, combined)
    return combined

# ==========================================================
# ====================== SGO EVENTS ========================
# ==========================================================
from datetime import timezone, timedelta

def get_sgo_soccer_events_today():
    print("üìÖ Fetching today's Premier League events (SGO)...")

    # Build UTC date window for "today"
    now = datetime.now(timezone.utc)
    start = now.replace(hour=0, minute=0, second=0, microsecond=0)
    end = start + timedelta(days=1)

    params = {
        "apiKey": SGO_API_KEY,
        "sportID": "SOCCER",
        "leagueID": LEAGUE_ID,          # ENG_PR
        "oddsAvailable": "true",
        "bookmakerID": BOOKMAKER,
        "startsAfter": start.isoformat(),
        "startsBefore": end.isoformat(),
        "limit": 200,
    }

    r = requests.get(BASE_URL, params=params, timeout=25)

    if r.status_code != 200:
        print(f"[ERROR] SGO HTTP {r.status_code}: {r.text}")
        return []

    data = r.json().get("data", [])
    if not data:
        return []

    events = []
    for ev in data:
        try:
            home = ev["teams"]["home"]["names"]["long"]
            away = ev["teams"]["away"]["names"]["long"]
            events.append({
                "label": f"{away} @ {home}",
                "home": home,
                "away": away,
            })
        except:
            continue

    print(f"‚úÖ Found {len(events)} Premier League matches today")
    return events




# ==========================================================
# ====================== PROCESSING ========================
# ==========================================================
def process_player(player):
    df = get_recent_games(player["name"], player["url"])
    if df.empty or not is_regular_starter(df):
        return []

    rows = []
    df_eval = df.head(NUM_GAMES)

    for stat in STATS:
        meta = STAT_META[stat]
        col = meta["df_col"]

        if col not in df_eval.columns:
            continue

        series = pd.to_numeric(df_eval[col], errors="coerce").dropna()
        if series.empty:
            continue

        for thr in meta["thresholds"]:
            pct, hits, total = hit_rate(series, thr)
            if pct < 70 or total < 8:
                continue

            multi = multi_window_hit_rates(df, col, thr)
            stab = stability_score(multi)

            rows.append({
                "player": player["name"],
                "team": player["team"],
                "stat": meta["label"],
                "threshold": thr,
                "hit_rate": pct,
                "hits": hits,
                "total": total,
                "multi": multi,
                "stability": stab,
            })

    return rows

# ==========================================================
# ========================= MAIN ===========================
# ==========================================================
def main():
    print("=======================================")
    print("‚öΩ PL Shots / SOT ‚Äî SGO Slate")
    print("=======================================")

    events = get_sgo_soccer_events_today()
    if not events:
        print("‚ö†Ô∏è No EPL games today.")
        return

    teams_today = set()
    for e in events:
        teams_today.add(e["home"])
        teams_today.add(e["away"])

    players = fetch_player_index()
    rows = []

    print(f"üìå Processing players from {len(teams_today)} teams")

    for p in players:
        if p["team"] not in teams_today:
            continue
        try:
            rows.extend(process_player(p))
        except:
            continue

    if not rows:
        print("No qualifying plays found.")
        return

    # dedupe
    seen = set()
    uniq = []
    for r in rows:
        k = (r["player"], r["stat"], r["threshold"])
        if k not in seen:
            seen.add(k)
            uniq.append(r)

    uniq = sorted(uniq, key=lambda r: (-r["stability"], -r["hit_rate"]))[:30]

    today = datetime.now().strftime("%Y-%m-%d")
    path = os.path.join(OUT_DIR, f"PL_{today}.txt")

    with open(path, "w", encoding="utf-8") as f:
        f.write("‚öΩ Premier League ‚Äî Shots & SOT Hit Rates\n\n")
        f.write("Today's Matches:\n")
        for e in events:
            f.write(f"‚Ä¢ {e['label']}\n")
        f.write("\n")

        for r in uniq:
            m = r["multi"]
            f.write(
                f"{short_name(r['player'])} ({r['team']}) ‚Äî "
                f"{r['stat']} {r['threshold']}+ | "
                f"{r['hits']}/{r['total']} | "
                f"L5 {m[5]['hits']}/5 "
                f"L10 {m[10]['hits']}/10 "
                f"L15 {m[15]['hits']}/15 | "
                f"Stab {r['stability']}\n"
            )

    print(f"üìÑ Output saved: {path}")
    print("‚úÖ Done.")

if __name__ == "__main__":
    main()
