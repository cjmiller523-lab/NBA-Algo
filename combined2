# combined_v2.py
import warnings
warnings.filterwarnings("ignore")

import os
import json
import random
import time
from math import ceil
from datetime import datetime

import numpy as np
import pandas as pd
import requests

# nba_api
from nba_api.stats.endpoints import PlayerGameLog
from nba_api.stats.static import players as nba_players

# PDF
from reportlab.lib.pagesizes import letter
from reportlab.lib import colors
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle
from reportlab.lib.styles import getSampleStyleSheet


# ==============================
# SETTINGS
# ==============================
NUM_GAMES = 10
SEASONS = ["2025-26", "2024-25"]
SEASON_TYPES = ["Regular Season", "Playoffs"]
MAX_RETRIES = 3
ODDS_CUTOFF = -600  # exclude <= -600

# Threshold ladders (used only when we need a “ladder” reference; we primarily ceil(line))
POINT_THRESHOLDS = [10, 15, 20, 25, 30]
REB_THRESHOLDS   = [2, 4, 6, 8, 10]
AST_THRESHOLDS   = [2, 4, 6, 8, 10]
STL_THRESHOLDS   = [1, 2, 3, 4]
BLK_THRESHOLDS   = [1, 2, 3, 4]
THREEPM_THRESHOLDS = [1, 2, 3, 4, 5]

STAT_META = {
    "points":   {"label": "Points",   "df_col": "PTS",  "thresholds": POINT_THRESHOLDS},
    "rebounds": {"label": "Rebounds", "df_col": "REB",  "thresholds": REB_THRESHOLDS},
    "assists":  {"label": "Assists",  "df_col": "AST",  "thresholds": AST_THRESHOLDS},
    "steals":   {"label": "Steals",   "df_col": "STL",  "thresholds": STL_THRESHOLDS},
    "blocks":   {"label": "Blocks",   "df_col": "BLK",  "thresholds": BLK_THRESHOLDS},
    "threes":   {"label": "3PM",      "df_col": "FG3M", "thresholds": THREEPM_THRESHOLDS},
}
STATS = list(STAT_META.keys())

# SGO (odds) config
SGO_API_KEY = os.getenv("SGO_API_KEY", "7243468c02f981445249730c03b426c1")
BASE_URL    = "https://api.sportsgameodds.com/v2/events"

# Cache dirs/files
ODDS_CACHE_DIR   = "odds_cache"
PLAYER_CACHE_DIR = "cache"
ID_CACHE_FILE    = "player_id_cache.json"
os.makedirs(ODDS_CACHE_DIR, exist_ok=True)
os.makedirs(PLAYER_CACHE_DIR, exist_ok=True)


# ==============================
# UTILS
# ==============================
def _safe_filename(name: str) -> str:
    return (
        name.replace(" ", "_")
            .replace(".", "")
            .replace("'", "")
            .replace("/", "_")
            .replace("\\", "_")
    )

def _today_tag():
    return datetime.utcnow().strftime("%Y%m%d")


# ==============================
# PLAYER ID CACHE (critical fix)
# ==============================
def _load_id_cache():
    if os.path.exists(ID_CACHE_FILE):
        try:
            with open(ID_CACHE_FILE, "r") as f:
                return json.load(f)
        except:
            return {}
    return {}

def _save_id_cache(cache):
    with open(ID_CACHE_FILE, "w") as f:
        json.dump(cache, f, indent=2)

def name_to_nba_id(player_name: str):
    """
    Resolve NBA player ID for a given name.
    - Cache results locally
    - Return None if not found (rookies, 2-ways, G-League call-ups)
    """
    cache = _load_id_cache()
    if player_name in cache:
        return cache[player_name]

    found = nba_players.find_players_by_full_name(player_name)
    if not found:
        cache[player_name] = None
    else:
        cache[player_name] = found[0]["id"]

    _save_id_cache(cache)
    return cache[player_name]


# ==============================
# NBA GAMELOG CACHE (Script A style)
# ==============================
def load_cache_player(player_name):
    path = os.path.join(PLAYER_CACHE_DIR, f"{_safe_filename(player_name)}.json")
    if os.path.exists(path):
        try:
            with open(path, "r") as f:
                data = json.load(f)
            df = pd.DataFrame(data)
            if not df.empty and "GAME_DATE" in df.columns:
                df["GAME_DATE"] = pd.to_datetime(df["GAME_DATE"], errors="coerce")
            return df.to_dict(orient="records")
        except Exception as e:
            print(f"  ⚠️ Error loading cache for {player_name}: {e}")
            return []
    return []

def save_cache_player(player_name, data):
    path = os.path.join(PLAYER_CACHE_DIR, f"{_safe_filename(player_name)}.json")
    with open(path, "w") as f:
        json.dump(data, f, indent=2, default=str)

def safe_fetch_player_logs(player_id, season, stype):
    for attempt in range(MAX_RETRIES):
        try:
            time.sleep(random.uniform(0.25, 0.6))  # polite delay
            return PlayerGameLog(
                player_id=player_id,
                season=season,
                season_type_all_star=stype
            ).get_data_frames()[0]
        except Exception as e:
            print(f"   ⚠️ Attempt {attempt+1} failed for {player_id}: {e}")
            time.sleep(1.5 + attempt)
    print(f"   ❌ Skipping {player_id} after {MAX_RETRIES} failed attempts.")
    return pd.DataFrame()

def get_recent_games_cached_nba(player_name, player_id):
    """Return last NUM_GAMES from NBA API, cached per player."""
    player_cache = load_cache_player(player_name)
    df_cached = pd.DataFrame(player_cache)
    if not df_cached.empty:
        df_cached["GAME_DATE"] = pd.to_datetime(df_cached["GAME_DATE"], errors="coerce")

    fetched_df = pd.DataFrame()
    for season in SEASONS:
        for stype in SEASON_TYPES:
            logs = safe_fetch_player_logs(player_id, season, stype)
            if not logs.empty:
                fetched_df = pd.concat([fetched_df, logs], ignore_index=True)

    if fetched_df.empty:
        print(f"  ⚠️ No NBA API data for {player_name}, using cache only.")
        return df_cached.head(NUM_GAMES)

    fetched_df["GAME_DATE"] = pd.to_datetime(fetched_df["GAME_DATE"], errors="coerce")
    fetched_df = fetched_df[["GAME_DATE", "MATCHUP", "MIN", "PTS", "REB", "AST", "STL", "BLK", "FG3M"]]
    fetched_df.sort_values("GAME_DATE", ascending=False, inplace=True)
    fetched_df = fetched_df.head(NUM_GAMES)

    if df_cached.empty:
        combined = fetched_df
    else:
        combined = pd.concat([fetched_df, df_cached], ignore_index=True)
        combined["GAME_DATE"] = pd.to_datetime(combined["GAME_DATE"], errors="coerce")
        combined = (combined.drop_duplicates(subset="GAME_DATE")
                            .sort_values("GAME_DATE", ascending=False)
                            .head(NUM_GAMES))

    save_cache_player(player_name, combined.to_dict(orient="records"))
    return combined


# ==============================
# SGO CACHE (odds)
# ==============================
def get_odds_cache_path(tag):
    return os.path.join(ODDS_CACHE_DIR, f"{_safe_filename(tag)}_{_today_tag()}.json")

def load_cached_odds(tag):
    p = get_odds_cache_path(tag)
    if os.path.exists(p):
        try:
            with open(p, "r") as f:
                return json.load(f)
        except:
            return None
    return None

def save_cached_odds(data, tag):
    with open(get_odds_cache_path(tag), "w") as f:
        json.dump(data, f, indent=2)


# ==============================
# SGO API
# ==============================
def get_all_games_today_sgo():
    params = {
        "apiKey": SGO_API_KEY,
        "leagueID": "NBA",
        "oddsAvailable": "true",
        "bookmakerID": "fanduel",
        "limit": "200",
    }
    r = requests.get(BASE_URL, params=params, timeout=25)
    r.raise_for_status()
    js = r.json()
    return js.get("data", [])

def pick_starters(team_players: dict):
    """
    Improved starters:
    1) Use 'starter' flag if present
    2) Else top 5 by 'avgMinutes' if present
    3) Else fallback: first 5 by sorted playerID
    """
    # 1) explicit starter flag
    starters = [pid for pid, p in team_players.items() if p.get("starter") is True]
    if len(starters) >= 5:
        return starters[:5]

    # 2) top by avgMinutes
    if any("avgMinutes" in p for p in team_players.values()):
        ranked = sorted(team_players.items(), key=lambda kv: -float(kv[1].get("avgMinutes", 0)))
        return [pid for pid, _ in ranked[:5]]

    # 3) deterministic fallback
    return sorted(team_players.keys())[:5]

def build_odds_request(player_ids):
    odd_ids = []
    for pid in player_ids:
        for stat in STATS:
            odd_ids.append(f"{stat}-{pid}-game-ou-over")
    return ",".join(odd_ids)

def fetch_team_props(odd_id_string, tag):
    cached = load_cached_odds(tag)
    if cached:
        return cached

    params = {
        "apiKey": SGO_API_KEY,
        "leagueID": "NBA",
        "bookmakerID": "fanduel",
        "oddsAvailable": "true",
        "oddIDs": odd_id_string,
        "includeOpposingOdds": "true",
        "includeAltLines": "true",
        "limit": "1",
    }
    for attempt in range(4):
        r = requests.get(BASE_URL, params=params, timeout=25)
        js = r.json()
        if "data" in js and js["data"]:
            save_cached_odds(js, tag)
            return js
        time.sleep(1 + attempt * 0.5)

    return None

def parse_props(player_id, stat, odds_obj):
    odd_id = f"{stat}-{player_id}-game-ou-over"
    if odd_id not in odds_obj:
        return []

    node = odds_obj[odd_id]
    bm = node.get("byBookmaker", {})
    if "fanduel" not in bm:
        return []

    out = []
    # main
    try:
        out.append({
            "overUnder": float(node["bookOverUnder"]),
            "odds": int(bm["fanduel"]["odds"]),
            "is_main": True,
        })
    except Exception:
        pass

    # alts
    for alt in bm["fanduel"].get("altLines", []):
        try:
            out.append({
                "overUnder": float(alt["overUnder"]),
                "odds": int(alt["odds"]),
                "is_main": False,
            })
        except Exception:
            continue

    return out

def filter_juiced(lines):
    clean = []
    for x in lines:
        try:
            if int(x["odds"]) >= ODDS_CUTOFF:
                clean.append(x)
        except:
            continue
    return clean


# ==============================
# CONFIDENCE / EDGE
# ==============================
def hit_rate(series, threshold):
    s = pd.to_numeric(series, errors="coerce").dropna()
    total = len(s)
    if total == 0:
        return 0.0, 0, 0
    hits = int((s >= threshold).sum())
    pct = hits / total * 100
    return round(pct, 1), hits, total

def compute_confidence(df, stat_col, threshold):
    if df.empty or stat_col not in df.columns:
        return 0.0

    vals = pd.to_numeric(df[stat_col], errors="coerce").dropna().tolist()
    if not vals:
        return 0.0

    mins = pd.to_numeric(df.get("MIN", pd.Series([0]*len(vals))), errors="coerce").fillna(0).tolist()
    total = len(vals)

    base_hits = sum(v >= threshold for v in vals)
    base_pct = base_hits / total * 100

    median_min = np.median([m for m in mins if m > 0]) if any(m > 0 for m in mins) else None

    penalties = 0.0
    ignorable_miss = 0
    for v, m in zip(vals, mins):
        if v >= threshold:
            continue
        gap = threshold - v
        low_min = (median_min is not None and m < 0.6 * median_min)
        close_miss = gap <= 1.5  # tighter “close” window

        if low_min or close_miss:
            ignorable_miss += 1
            continue

        penalties += min(gap * 1.8, 12)  # sharper penalty

    outlier_bonus = 0
    if base_hits >= 1 and penalties == 0 and ignorable_miss > 0:
        outlier_bonus = 5

    stat_std = float(np.std(vals))
    if stat_std <= 2:
        consistency_bonus = 6
    elif stat_std <= 4:
        consistency_bonus = 3
    else:
        consistency_bonus = 0

    conf = base_pct + outlier_bonus + consistency_bonus - penalties
    return float(max(0, min(100, round(conf, 1))))

def american_to_implied_prob(odds):
    try:
        o = int(odds)
    except Exception:
        return 0.0
    if o == 0:
        return 0.0
    if o < 0:
        return (-o) / ((-o) + 100)
    return 100 / (o + 100)


# ==============================
# (Option 3) SGO stats fallback
# NOTE: This stub returns None by default because SGO public docs for
# player box-score logs aren’t guaranteed. If you later share an endpoint,
# plug it here to return a DataFrame with same columns as NBA logs.
# ==============================
def get_recent_games_cached_sgo(player_obj, num_games=NUM_GAMES):
    """
    Expected return: DataFrame with columns:
      ["GAME_DATE","MATCHUP","MIN","PTS","REB","AST","STL","BLK","FG3M"]
    If unavailable, return empty DataFrame.
    """
    # Placeholder – returns empty to gracefully skip if NBA logs missing.
    # If you have SGO boxscore endpoint, implement it here.
    return pd.DataFrame()


# ==============================
# CORE MERGE: GAMES → PROPS → HIT RATES
# ==============================
def rounded_threshold_from_line(line_val: float) -> int:
    """Convert a prop line like 2.5 → 3; 7.5 → 8."""
    return int(ceil(line_val))

def process_all_games():
    games = get_all_games_today_sgo()
    if not games:
        print("⚠️ No games returned from SGO.")
        return []

    results = []

    for game in games:
        if "players" not in game:
            print("  ⚠️ Game has no player data — skipping.")
            continue

        home = game["teams"]["home"]
        away = game["teams"]["away"]
        players_dict = game["players"]

        home_team_name = home["names"]["medium"]
        away_team_name = away["names"]["medium"]
        game_label = f"{away_team_name} @ {home_team_name}"

        print("\n==============================")
        print(game_label)
        print("==============================")

        # split players by teamID
        home_players = {pid: p for pid, p in players_dict.items() if p["teamID"] == home["teamID"]}
        away_players = {pid: p for pid, p in players_dict.items() if p["teamID"] == away["teamID"]}

        home_starters = pick_starters(home_players)
        away_starters = pick_starters(away_players)

        home_req = build_odds_request(home_starters)
        away_req = build_odds_request(away_starters)

        home_data = fetch_team_props(home_req, tag=f"{home_team_name}")
        away_data = fetch_team_props(away_req, tag=f"{away_team_name}")

        if not home_data or "data" not in home_data or not home_data["data"]:
            print("  ⚠️ Home team props unavailable — skipping game.")
            continue
        if not away_data or "data" not in away_data or not away_data["data"]:
            print("  ⚠️ Away team props unavailable — skipping game.")
            continue

        home_odds_obj = home_data["data"][0]["odds"]
        away_odds_obj = away_data["data"][0]["odds"]

        game_rows = []

        def process_side(team_players, starter_ids, odds_obj, team_name):
            for pid in starter_ids:
                player = team_players.get(pid)
                if not player:
                    continue
                name = player.get("name")
                if not name:
                    continue

                # ===== ID resolve (fixed) =====
                nba_id = name_to_nba_id(name)

                # Pull stats via NBA → fallback SGO → else skip
                df = pd.DataFrame()
                if nba_id is not None:
                    df = get_recent_games_cached_nba(name, nba_id)
                if (df is None or df.empty):
                    df = get_recent_games_cached_sgo(player, NUM_GAMES)
                if df is None or df.empty:
                    print(f"  ⚠️ No game logs for {name} — skipping.")
                    continue

                for stat_key in STATS:
                    stat_info = STAT_META[stat_key]
                    df_col = stat_info["df_col"]

                    if df_col not in df.columns:
                        continue

                    props = parse_props(pid, stat_key, odds_obj)
                    if not props:
                        continue

                    props = filter_juiced(props)
                    if not props:
                        continue

                    for prop in props:
                        line_val = float(prop["overUnder"])
                        odds_val = int(prop["odds"])

                        thr = rounded_threshold_from_line(line_val)

                        pct, hits, total = hit_rate(df[df_col], thr)
                        conf = compute_confidence(df, df_col, thr)
                        implied = american_to_implied_prob(odds_val) * 100
                        edge = round(conf - implied, 1)

                        game_rows.append({
                            "game": game_label,
                            "team": team_name,
                            "player": name,
                            "stat": stat_info["label"],
                            "line": line_val,
                            "odds": odds_val,
                            "threshold": thr,
                            "hit_rate": pct,
                            "hits": hits,
                            "total": total,
                            "confidence": conf,
                            "edge": edge,
                            "is_main": prop.get("is_main", False),
                        })

        process_side(away_players, away_starters, away_odds_obj, away_team_name)
        process_side(home_players, home_starters, home_odds_obj, home_team_name)

        if game_rows:
            # rank: Conf → Edge → Hit%
            ranked = sorted(game_rows, key=lambda r: (-r["confidence"], -r["edge"], -r["hit_rate"]))[:10]

            print("\nTop 10 Props (Conf → Edge → Hit%):")
            for r in ranked:
                print(
                    f"{r['player']} ({r['team']}) | {r['stat']} {r['line']} @ {r['odds']}  "
                    f"| Hit {r['hits']}/{r['total']} ({r['hit_rate']}%)  "
                    f"| Conf {r['confidence']}  | Edge {r['edge']}"
                )

            results.append({"game_label": game_label, "rows": ranked})
        else:
            print("  ⚠️ No valid props with game-log data for this game.")

    return results


# ==============================
# PDF REPORT
# ==============================
def build_pdf_report(all_game_results):
    if not all_game_results:
        print("⚠️ Nothing to write to PDF.")
        return

    today_str = datetime.now().strftime("%Y-%m-%d")
    pdf_filename = f"NBA_Props_Confidence_{today_str}.pdf"

    doc = SimpleDocTemplate(pdf_filename, pagesize=letter)
    styles = getSampleStyleSheet()
    story = []

    story.append(Paragraph(f"NBA Props Confidence Report – {today_str}", styles["Title"]))
    story.append(Spacer(1, 12))

    for game in all_game_results:
        story.append(Paragraph(f"<b>{game['game_label']}</b>", styles["Heading2"]))
        story.append(Spacer(1, 6))

        data = [["Player", "Team", "Stat", "Line", "Odds", "Thr", "Hit", "Hit%", "Conf", "Edge"]]
        for r in game["rows"]:
            data.append([
                r["player"],
                r["team"],
                r["stat"],
                f"{r['line']}",
                f"{r['odds']}",
                f"{r['threshold']}+",
                f"{r['hits']}/{r['total']}",
                f"{r['hit_rate']}%",
                f"{r['confidence']}",
                f"{r['edge']}",
            ])

        t = Table(data)
        t.setStyle(TableStyle([
            ("BACKGROUND", (0, 0), (-1, 0), colors.lightgrey),
            ("GRID", (0, 0), (-1, -1), 0.5, colors.grey),
            ("FONTNAME", (0, 0), (-1, 0), "Helvetica-Bold"),
            ("ALIGN", (3, 1), (-1, -1), "CENTER"),
        ]))

        story.append(t)
        story.append(Spacer(1, 12))

    doc.build(story)
    print(f"\n✅ PDF report saved to {pdf_filename}")


# ==============================
# MAIN
# ==============================
def main():
    results = process_all_games()
    build_pdf_report(results)

if __name__ == "__main__":
    main()
