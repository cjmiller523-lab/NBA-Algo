import os
import json
import time
import re
import requests
import pandas as pd
from datetime import datetime
from collections import defaultdict
from io import StringIO

TEAM_LIST_URL = "https://statsapi.web.nhl.com/api/v1/teams"

# ==========================================================
# CONFIG
# ==========================================================

NUM_GAMES = 10
MIN_AVG_TOI = 10.0
SEASON_ID = "20252026"
GAME_TYPE = 2

CACHE_TTL_HOURS = 0

SOG_THRESHOLDS = [2, 3, 4, 5, 6]
PTS_THRESHOLDS = [1, 2, 3]
BLK_THRESHOLDS = [1, 2, 3]   # ‚úÖ NEW

CACHE_DIR = "nhl_cache/player_logs"
TWITTER_DIR = "twitter_posts"

os.makedirs(CACHE_DIR, exist_ok=True)
os.makedirs(TWITTER_DIR, exist_ok=True)

HTTP_HEADERS = {
    "User-Agent": "Mozilla/5.0 nhl-prop-model/1.0"
}

# ==========================================================
# HELPERS
# ==========================================================

def debug(msg):
    print(f"[DEBUG] {msg}")

def normalize_name(val):
    if isinstance(val, dict):
        return val.get("default", "")
    return val or ""

def name_key(name):
    name = (name or "").lower().strip()
    name = re.sub(r"[^a-z\s\-']", "", name)
    name = re.sub(r"\s+", " ", name)
    return name

# ==========================================================
# TIERS
# ==========================================================

def get_tier(hits):
    if hits == 10:
        return "LOCK"
    elif hits == 9:
        return "T1"
    elif hits == 8:
        return "T2"
    return None

# ==========================================================
# CONFIDENCE (NHL-TUNED)
# ==========================================================

def calc_confidence(hits, threshold, opp_sa, league_sa):
    hr = hits / NUM_GAMES

    # NHL tuned scaling
    base = (hr - 0.75) / 0.25
    base = max(0.0, min(1.0, base))

    # Threshold boost (small)
    th_boost = min(0.15, max(0.0, (threshold - 1) * 0.04))

    # Opponent boost (optional)
    opp_boost = 0.0
    if opp_sa and league_sa:
        diff = (opp_sa - league_sa) / league_sa
        opp_boost = max(-0.08, min(0.12, diff * 0.75))

    score = base + th_boost + opp_boost
    score = max(0.0, min(1.0, score))

    return int(round(score * 100))

# ==========================================================
# NHL DATA
# ==========================================================

def get_todays_games():
    today = datetime.now().strftime("%Y-%m-%d")
    url = f"https://api-web.nhle.com/v1/schedule/{today}"

    r = requests.get(url, headers=HTTP_HEADERS, timeout=10)
    r.raise_for_status()
    data = r.json()

    games = []
    for day in data.get("gameWeek", []):
        if day.get("date") != today:
            continue
        for g in day.get("games", []):
            games.append({
                "home": g["homeTeam"]["abbrev"],
                "away": g["awayTeam"]["abbrev"],
            })

    debug(f"Found {len(games)} games TODAY")
    return games

def get_team_roster(team):
    url = f"https://api-web.nhle.com/v1/roster/{team}/current"
    r = requests.get(url, headers=HTTP_HEADERS, timeout=10)
    r.raise_for_status()
    data = r.json()

    players = []
    for p in data.get("forwards", []) + data.get("defensemen", []):
        name = (
            normalize_name(p.get("fullName"))
            or normalize_name(p.get("defaultName"))
            or f"{normalize_name(p.get('firstName'))} {normalize_name(p.get('lastName'))}"
        ).strip()

        players.append({
            "id": p["id"],
            "name": name,
            "team": team,
            "position": (p.get("positionCode") or p.get("position") or "").upper()  # ‚úÖ NEW (helps if you want to filter later)
        })

    return players

def get_player_log(pid, force_refresh=False):
    path = f"{CACHE_DIR}/{pid}.json"
    # Use cached file if it exists and is fresh (unless force_refresh=True).
    if os.path.exists(path) and not force_refresh:
        try:
            mtime = os.path.getmtime(path)
            age = time.time() - mtime
            if age < CACHE_TTL_HOURS * 3600:
                with open(path, "r", encoding="utf-8") as f:
                    return json.load(f)
        except Exception:
            pass

    url = f"https://api-web.nhle.com/v1/player/{pid}/game-log/{SEASON_ID}/{GAME_TYPE}"
    r = requests.get(url, headers=HTTP_HEADERS, timeout=10)
    r.raise_for_status()
    data = r.json()

    try:
        with open(path, "w", encoding="utf-8") as f:
            json.dump(data, f)
    except Exception:
        pass

    time.sleep(0.15)
    return data

# ==========================================================
# INJURIES (ESPN)
# ==========================================================

def get_injured_players():
    url = "https://www.espn.com/nhl/injuries"
    r = requests.get(url, headers=HTTP_HEADERS, timeout=15)
    r.raise_for_status()

    tables = pd.read_html(StringIO(r.text))
    injured = set()

    BAD = {"OUT", "INJURED RESERVE", "IR", "SUSPENSION"}

    for df in tables:
        cols = [c.upper() for c in df.columns.astype(str)]
        if "NAME" not in cols or "STATUS" not in cols:
            continue

        name_col = df.columns[cols.index("NAME")]
        status_col = df.columns[cols.index("STATUS")]

        for _, row in df.iterrows():
            status = str(row.get(status_col, "")).upper()
            if status in BAD:
                raw = str(row.get(name_col, ""))
                raw = re.sub(r"(LW|RW|C|D|G)$", "", raw).strip()
                injured.add(name_key(raw))

    debug(f"Injuries found: {len(injured)}")
    return injured

# ==========================================================
# STATS
# ==========================================================

def get_last_games(log):
    games = log.get("gameLog", [])
    games = sorted(games, key=lambda x: x.get("gameDate", ""), reverse=True)
    return games[:NUM_GAMES]

def parse_toi(v):
    if not v or ":" not in str(v):
        return 0
    m, s = str(v).split(":")
    return int(m) + int(s)/60

def avg_toi(log):
    g = get_last_games(log)
    if len(g) < NUM_GAMES:
        return 0
    return sum(parse_toi(x.get("toi") or x.get("timeOnIce")) for x in g) / len(g)

def get_shots(log):
    return [int(x.get("shots", 0)) for x in get_last_games(log)]

def get_points(log):
    pts = []
    for g in get_last_games(log):
        pts.append(int(g.get("goals", 0)) + int(g.get("assists", 0)))
    return pts

# ‚úÖ NEW: robust blocked shots getter
def get_blocks(log):
    vals = []
    for g in get_last_games(log):
        v = (
            g.get("blockedShots")
            or g.get("blocks")
            or g.get("blocked")
            or g.get("blk")
            or 0
        )
        try:
            vals.append(int(v))
        except Exception:
            vals.append(0)
    return vals

def hit_rate(vals, t):
    return sum(v >= t for v in vals), len(vals)

# ==========================================================
# TWITTER SAVE + RECAP
# ==========================================================

def save_twitter_best_bets(best_sog, best_pts, best_blk):
    path = f"{TWITTER_DIR}/nhl_best_bets_{datetime.now().strftime('%Y-%m-%d')}.txt"

    lines = []
    lines.append("üî• NHL BEST BETS ‚Äî Shots, Points, Blocks")
    lines.append("")

    all_matchups = sorted(set(list(best_sog.keys()) + list(best_pts.keys()) + list(best_blk.keys())))
    for matchup in all_matchups:
        lines.append(matchup)

        if best_sog.get(matchup):
            lines.append("SOG:")
            for r in best_sog[matchup]:
                lines.append(f"‚≠ê {r['player']} ‚Äî SOG {r['threshold']}+ | {r['hits']}/10")

        if best_pts.get(matchup):
            lines.append("PTS:")
            for r in best_pts[matchup]:
                lines.append(f"‚≠ê {r['player']} ‚Äî PTS {r['threshold']}+ | {r['hits']}/10")

        if best_blk.get(matchup):
            lines.append("BLK:")
            for r in best_blk[matchup]:
                lines.append(f"‚≠ê {r['player']} ‚Äî BLK {r['threshold']}+ | {r['hits']}/10")

        lines.append("")

    with open(path, "w", encoding="utf-8") as f:
        f.write("\n".join(lines))

    # Append yesterday's graded recap to the twitter post (if available)
    try:
        picks = load_yesterdays_nhl_picks()
        picks = dedup_picks_keep_highest(picks)
        if picks:
            recap_lines = ["", "üìä YESTERDAY RECAP", "--------------------"]
            graded = []
            for p in picks:
                g = grade_nhl_yesterdays_pick(p)
                if g:
                    graded.append(g)

            if not graded:
                recap_lines.append("No yesterday picks graded.")
            else:
                for g in graded:
                    emoji = "‚úÖ" if g['hit'] else "‚ùå"
                    recap_lines.append(
                        f"{emoji} {g['player']} - {g['market']} {g['threshold']}+ ‚Üí {g['value']}"
                    )

            with open(path, "a", encoding="utf-8") as f:
                f.write("\n" + "\n".join(recap_lines))
    except Exception:
        pass

    debug(f"Twitter text saved to {path}")

def load_yesterdays_nhl_picks():
    """
    Parse yesterday's nhl_best_bets_YYYY-MM-DD.txt and return list of picks
    each pick: {player, market, threshold}
    """
    yday = (datetime.now() - pd.Timedelta(days=1)).strftime('%Y-%m-%d')
    path = f"{TWITTER_DIR}/nhl_best_bets_{yday}.txt"
    if not os.path.exists(path):
        return []

    picks = []
    with open(path, 'r', encoding='utf-8') as f:
        for raw in f:
            line = raw.strip()
            if not line or not line.startswith('‚≠ê'):
                continue
            # Examples:
            # ‚≠ê {player} ‚Äî SOG {threshold}+ | {hits}/10
            # ‚≠ê {player} ‚Äî PTS {threshold}+ | {hits}/10
            # ‚≠ê {player} ‚Äî BLK {threshold}+ | {hits}/10
            m = re.search(r'^‚≠ê\s+(.*?)\s+‚Äî\s+(SOG|PTS|BLK)\s+(\d+)\+\s+\|', line)
            if m:
                picks.append({
                    'player': m.group(1).strip(),
                    'market': m.group(2),
                    'threshold': int(m.group(3)),
                })
    return picks

def get_all_team_abbrevs():
    try:
        r = requests.get(TEAM_LIST_URL, headers=HTTP_HEADERS, timeout=10)
        r.raise_for_status()
        data = r.json()
        return [t.get('abbreviation') for t in data.get('teams', []) if t.get('abbreviation')]
    except Exception:
        return ['ANA','ARI','BOS','BUF','CGY','CAR','CHI','COL','CBJ','DAL','DET','EDM','FLA','LAK',
                'MIN','MTL','NSH','NJD','NYI','NYR','OTT','PHI','PIT','SJS','SEA','STL','TBL','TOR','VAN','VGK','WPG','WSH']

def resolve_player_to_id(player_name):
    """Try to resolve a player full name to an NHL player id by scanning team rosters."""
    target = name_key(player_name)
    for team in get_all_team_abbrevs():
        try:
            roster = get_team_roster(team)
            for p in roster:
                if name_key(p['name']) == target:
                    return p['id']
        except Exception:
            continue
    return None

def grade_nhl_yesterdays_pick(pick):
    pid = resolve_player_to_id(pick['player'])
    if not pid:
        return None
    log = get_player_log(pid)
    games = get_last_games(log)
    if not games:
        return None

    last = games[0]
    if pick['market'] == 'SOG':
        val = int(last.get('shots', 0))
    elif pick['market'] == 'PTS':
        val = int(last.get('goals', 0)) + int(last.get('assists', 0))
    else:  # BLK
        v = last.get("blockedShots") or last.get("blocks") or last.get("blocked") or last.get("blk") or 0
        try:
            val = int(v)
        except Exception:
            val = 0

    return {
        'player': pick['player'],
        'market': pick['market'],
        'threshold': pick['threshold'],
        'value': val,
        'hit': val >= pick['threshold']
    }

def dedup_picks_keep_highest(picks):
    """
    Deduplicate picks by (player, market).
    Keep only the highest threshold for each combo.
    """
    by_combo = {}
    for p in picks:
        key = (p['player'], p['market'])
        if key not in by_combo or p['threshold'] > by_combo[key]['threshold']:
            by_combo[key] = p
    return list(by_combo.values())

def save_full_results(results, fname):
    path = f"nhl_cache/{fname}"
    with open(path, "w", encoding="utf-8") as f:
        json.dump(results, f, indent=2)

# ==========================================================
# MAIN
# ==========================================================

def main():
    debug("===== NHLV11 START =====")

    injured = get_injured_players()
    games = get_todays_games()

    players = []
    seen = set()

    for g in games:
        matchup = f"{g['away']} @ {g['home']}"
        for team, opp in [(g["home"], g["away"]), (g["away"], g["home"])]:
            for p in get_team_roster(team):
                if p["id"] in seen:
                    continue
                if name_key(p["name"]) in injured:
                    continue

                p["matchup"] = matchup
                p["opp"] = opp
                players.append(p)
                seen.add(p["id"])

    debug(f"Total players today: {len(players)}")

    results_sog = []
    results_pts = []
    results_blk = []

    for p in players:
        try:
            log = get_player_log(p["id"])
            if len(log.get("gameLog", [])) < NUM_GAMES:
                continue
            if avg_toi(log) < MIN_AVG_TOI:
                continue

            shots = get_shots(log)
            pts = get_points(log)
            blks = get_blocks(log)

            for t in SOG_THRESHOLDS:
                hits, _ = hit_rate(shots, t)
                tier = get_tier(hits)
                if not tier:
                    continue
                conf = calc_confidence(hits, t, None, None)
                if hits == 8 and conf < 45:
                    continue
                results_sog.append({
                    "market": "SOG",
                    "player": p["name"],
                    "matchup": p["matchup"],
                    "threshold": t,
                    "hits": hits,
                    "tier": tier,
                    "conf": conf
                })

            for t in PTS_THRESHOLDS:
                hits, _ = hit_rate(pts, t)
                tier = get_tier(hits)
                if not tier:
                    continue
                conf = calc_confidence(hits, t, None, None)
                if hits == 8 and conf < 45:
                    continue
                results_pts.append({
                    "market": "PTS",
                    "player": p["name"],
                    "matchup": p["matchup"],
                    "threshold": t,
                    "hits": hits,
                    "tier": tier,
                    "conf": conf
                })

            for t in BLK_THRESHOLDS:
                hits, _ = hit_rate(blks, t)
                tier = get_tier(hits)
                if not tier:
                    continue
                conf = calc_confidence(hits, t, None, None)
                if hits == 8 and conf < 45:
                    continue
                results_blk.append({
                    "market": "BLK",
                    "player": p["name"],
                    "matchup": p["matchup"],
                    "threshold": t,
                    "hits": hits,
                    "tier": tier,
                    "conf": conf
                })

        except Exception as e:
            print(f"[ERROR] {p['name']}: {e}")

    def best_per_game(results):
        out = defaultdict(list)
        rank = {"LOCK": 3, "T1": 2, "T2": 1}

        for r in results:
            out[r["matchup"]].append(r)

        final = {}
        for m, rows in out.items():
            by_combo = {}
            for r in rows:
                key = (r["player"], r["market"])
                if key not in by_combo or r["threshold"] > by_combo[key]["threshold"]:
                    by_combo[key] = r
            rows = list(by_combo.values())

            rows = sorted(
                rows,
                key=lambda x: (rank[x["tier"]], x["conf"], x["threshold"]),
                reverse=True
            )
            final[m] = rows[:4]

        return final

    best_sog = best_per_game(results_sog)
    best_pts = best_per_game(results_pts)
    best_blk = best_per_game(results_blk)

    save_twitter_best_bets(best_sog, best_pts, best_blk)

    # --------------------------------------------------
    # SAVE FULL SLATE FOR GROWTH SCRIPT / INTERNAL USE
    # --------------------------------------------------
    save_full_results(
        {
            "sog": results_sog,
            "pts": results_pts,
            "blk": results_blk,
        },
        f"nhl_full_{datetime.now().strftime('%Y-%m-%d')}.json"
    )

    print("\nüî• BEST BETS BY GAME\n")

    all_matchups = sorted(set(best_sog) | set(best_pts) | set(best_blk))
    for m in all_matchups:
        print(m)
        for r in best_sog.get(m, []):
            print(f" ‚≠ê {r['player']} ‚Äî SOG {r['threshold']}+ | {r['hits']}/10 | Conf {r['conf']}")
        for r in best_pts.get(m, []):
            print(f" ‚≠ê {r['player']} ‚Äî PTS {r['threshold']}+ | {r['hits']}/10 | Conf {r['conf']}")
        for r in best_blk.get(m, []):
            print(f" ‚≠ê {r['player']} ‚Äî BLK {r['threshold']}+ | {r['hits']}/10 | Conf {r['conf']}")
        print("")

    debug("===== NHLV11 END =====")


if __name__ == "__main__":
    main()
